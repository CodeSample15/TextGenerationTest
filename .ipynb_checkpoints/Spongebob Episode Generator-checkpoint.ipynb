{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b8ecbc4f",
   "metadata": {},
   "source": [
    "<h1>I hate myself for attempting this but I'm bored</h1>\n",
    "<br></br>\n",
    "<h3>Let me explain myself because I feel this needs explaining:</h3>\n",
    "<p>Recently, the GPT model has dominated the text-generation realm of AI (as it should, it's fucking amazing). However, I want to see how far I can push the RNN model for text generation before it can't be pushed any further. Of course, conditional text generation has been done before in the past with RNN, and very well, BUT: I am stubborn as fuck and need to experiment by myself to see what I can do. Also I just finished working on a video game and need an overcomplicated project to suck me back into the world of AI. I'll document my findings here in this notebook so you can see the deterioration of my sanity.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "daa4505f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-25T04:58:44.347663Z",
     "start_time": "2023-08-25T04:58:43.465080Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import glob\n",
    "from time import sleep\n",
    "\n",
    "from bs4 import BeautifulSoup as bs4\n",
    "import requests\n",
    "\n",
    "DESC_FILE = '../ep_descs.pkl'\n",
    "TRANS_FILE = 'D:/Machine Learning/Datasets/SpongeBob_SquarePants_Transcripts/'\n",
    "\n",
    "MAX_SEQ_LEN = 250"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6be69ec7",
   "metadata": {},
   "source": [
    "<h2>Problem #1: web scraping</h2>\n",
    "<br></br>\n",
    "<p>In order to get the generator to generate scripts from a prompt, I need to get descriptions of each episode (which will be the prompts of this generator). Fortunately, this data can be found on the Spongebob Wiki. Unfortunately, this means I have to do some mother-fucking web scraping. I'll try explain what I'm doing with comments but to be honest, I'm going to give up on that pretty quickly. Sorry in advance for my ugly python code</p>\n",
    "<p>For ease of use later on, I'll store the data (which will be kept in a dictionary) into a seperate file using python's pickle</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a2417651",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-24T02:14:57.532665Z",
     "start_time": "2023-08-24T02:14:53.478006Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished\n"
     ]
    }
   ],
   "source": [
    "#running for each season of spongebob\n",
    "SEASONS = 13\n",
    "data = {}\n",
    "\n",
    "for season in range(1, SEASONS+1):\n",
    "    page = requests.get(f\"https://spongebob.fandom.com/wiki/Season_{season}#List_of_episodes\").content\n",
    "    \n",
    "    soup = bs4(page, 'html.parser')\n",
    "    table = soup.find_all('table', class_='general')[0]\n",
    "        \n",
    "    #let's get the title and descriptions of each episode\n",
    "    titles = table.find_all('td', style='text-align:left')\n",
    "    descriptions = table.find_all('td', colspan='4')\n",
    "    \n",
    "    for j in range(len(titles)):\n",
    "        title = titles[j].text\n",
    "        desc = descriptions[j].text\n",
    "        #getting rid of the quotation marks around the episode name with possibly the most python line of code ever written (then also do some other pre processing)\n",
    "        title = title[1:-2]\n",
    "        title = title.replace(' ', '')\n",
    "        title = title.lower()\n",
    "        \n",
    "        data[title] = desc #updating the dataset\n",
    "        \n",
    "#save the compiled data to a file\n",
    "with open(DESC_FILE, 'wb') as f:\n",
    "    pickle.dump(data, f)\n",
    "\n",
    "print(\"Finished\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cceeadb8",
   "metadata": {},
   "source": [
    "<p>Alright, that wasn't as bad as I thought it would be. I ended up getting the script to work on the third or fourth time. Luckily the spongebob wiki doesn't require javascript to load its shit, so I didn't have to boot up selenium to get this scraper to work. Come to think of it, this was probably the best experience I've had writing a web scraper. Nice</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e18a47c",
   "metadata": {},
   "source": [
    "<h1>Problem #2: bringing both datasets together</h1>\n",
    "<br></br>\n",
    "<p>Now that I have all the data I need, I need to compile everything into a single dataset that I can use to train the network with. This means for the transcripts, I have to clean, tokenize, and pad everything. For the episode descriptions, I need to combine the descriptions with the correct transcripts.</p>\n",
    "<p>Some things to consider: RNN models are notoriously bad at generating long sequences of text. Should I set the sampling size lower so that the model performs better? Or should I keep it high so I can really test the limits of this type of model. Hmmmm.... I guess I'll figure it out as I go, but I'm pretty sure I'm going to have to set the sampling size to be smaller. I'll start with the full transcripts and go from there. I think the main reason I want to do this is because I already know how bad LSTM is at performing this task, but I haven't really tested the GRU layer that much and am curious as to how it performs. I think I'll end up training two models.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de593a2b",
   "metadata": {},
   "source": [
    "<h3>Quick side note:</h3>\n",
    "<p>I want to really quickly go over in text what I want the architecture of the model to be (inputs and outputs for now, I'll go into more detail when I build the model). For starters, the model will have two inputs: X1 and X2. They will store the previous text in the transcript and the prompt, respectively. The output will be a one-hot encoding of the next token to be added to the sequence. My hope with using the two seperate inputs for the model will help it perform better when generating scripts that are more relevant to the provided episode prompt. Again, GPT models handle this problem with ease, but when it comes to RNNs, I want to make sure the model remembers what it should be generating</p>\n",
    "<p>I'll go with this design for as long as possible, so hopefully I don't lose my shit trying to keep this plan from failing. I have to remember that this is not going to work the first time cuz I have no clue what the fuck I'm doing.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bc50dd7d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-25T04:58:49.443355Z",
     "start_time": "2023-08-25T04:58:49.345383Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "90 items failed to load\n",
      "303 items loaded!\n"
     ]
    }
   ],
   "source": [
    "#let's start with the basics: loading the data from disk\n",
    "dataset = {}\n",
    "\n",
    "descs = {}\n",
    "with open(DESC_FILE, 'rb') as f:\n",
    "    descs = pickle.load(f)\n",
    "\n",
    "failed_items = 0\n",
    "successful_items = 0\n",
    "    \n",
    "for file in glob.glob(TRANS_FILE + '*.txt'):\n",
    "    ep_title = file.split('\\\\')[1].split('.')[0]\n",
    "    ep_title = ep_title.lower()\n",
    "    \n",
    "    #try to access the description of the episode, if it's not on file, just ignore it\n",
    "    try:\n",
    "        desc = descs[ep_title]\n",
    "        \n",
    "        lines = []\n",
    "        with open(file, 'r') as f:\n",
    "            for line in f.readlines():\n",
    "                lines.append(line.lower())\n",
    "                #lines.extend('\\n')\n",
    "        \n",
    "        dataset[desc] = lines\n",
    "        successful_items += 1\n",
    "    except:\n",
    "        failed_items += 1\n",
    "        continue\n",
    "\n",
    "print(f\"{failed_items} items failed to load\")\n",
    "print(f\"{successful_items} items loaded!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1f6959a2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-25T05:01:16.056949Z",
     "start_time": "2023-08-25T05:01:13.960970Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing data...\n",
      "Finished\n"
     ]
    }
   ],
   "source": [
    "#alright, now let's process and organize this data (spaghetti code incoming)\n",
    "print(\"Processing data...\")\n",
    "\n",
    "pretokenized = []\n",
    "pretokenizedDescs = []\n",
    "\n",
    "def tokenize(line):\n",
    "    #not even going to explain this mess. Just know this cleans the data. Don't currently know a better way of doing this and it's killing me inside. \n",
    "    tokens = []\n",
    "    for char in line:\n",
    "        tokens.append(char)\n",
    "    return tokens\n",
    "\n",
    "for desc in dataset:\n",
    "    #clean the data\n",
    "    tempdata = [x for x in dataset[desc] if x != '\\n']\n",
    "    tokens = []\n",
    "    descTokens = []\n",
    "    \n",
    "    for line in tempdata:\n",
    "        line += \"\\n\"\n",
    "        tokens.extend(tokenize(line))\n",
    "        \n",
    "    pretokenizedDescs.append(tokenize(desc.lower()))\n",
    "    #removing unecessary tokens\n",
    "    pretokenizedDescs[-1].pop(pretokenizedDescs[-1].index('\\n'))\n",
    "    \n",
    "    pretokenized.append(tokens)\n",
    "    \n",
    "#now let's tokenize this sucker and then move on to building the dataset to be fed to the network.\n",
    "lib = [''] #library of tokens\n",
    "tokenized = [] #dataset tokenized\n",
    "tokenizedDescs = [] #same thing but descriptions\n",
    "maxLen = 0 #for padding later down the road\n",
    "maxDescLen = 0 #same thing but for descriptions\n",
    "\n",
    "#first the transcripts (calculating the maximum sequence length and then tokenizing the dataset using the lib array)\n",
    "for i in pretokenized:\n",
    "    if len(i) > maxLen:\n",
    "        maxLen = len(i)\n",
    "    for j in i:\n",
    "        if j not in lib:\n",
    "            lib.append(j)\n",
    "            \n",
    "for i in pretokenized:\n",
    "    temp = []\n",
    "    for j in i:\n",
    "        temp.append(lib.index(j))\n",
    "    tokenized.append(temp)\n",
    "    \n",
    "#now the descriptions\n",
    "for i in pretokenizedDescs:\n",
    "    if len(i) > maxDescLen:\n",
    "        maxDescLen = len(i)\n",
    "    for j in i: #continuing to build upon the library just in case there are some tokens that didn't make the list yet\n",
    "        if j not in lib:\n",
    "            lib.append(j)\n",
    "            \n",
    "for i in pretokenizedDescs:\n",
    "    temp = []\n",
    "    for j in i:\n",
    "        temp.append(lib.index(j))\n",
    "    tokenizedDescs.append(temp)\n",
    "    \n",
    "#now we need to pad the tokenized descriptions since that won't happen automatically when the dataset it built\n",
    "for i, n in enumerate(tokenizedDescs):\n",
    "    for j in range(MAX_SEQ_LEN-len(n)):\n",
    "        tokenizedDescs[i].append(0) #padding (0 token represents and empty string in the lib array)\n",
    "\n",
    "print(\"Finished\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ce3b6b91",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-25T05:04:28.193857Z",
     "start_time": "2023-08-25T05:04:28.175864Z"
    }
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import to_categorical\n",
    "import random\n",
    "\n",
    "#smallest length a sequence can be\n",
    "MIN_LEN = 5\n",
    "\n",
    "X1 = [] #ep descriptions\n",
    "X2 = [] #prev tokens\n",
    "Y = []  #ep transcipts\n",
    "\n",
    "#helper to generate random batches of data from the main dataset\n",
    "#loading the whole dataset to memory at one time on my 16GB of ram would fry my computer pretty quickly. Let's avoid that\n",
    "def get_dataset(batch_size, size=maxLen):\n",
    "    X1 = []\n",
    "    X2 = []\n",
    "    Y = []\n",
    "    for batch in range(batch_size):\n",
    "        rand_trans = random.randrange(MIN_LEN, len(tokenized)) #get a random transcript to get information from\n",
    "        rand_start = random.randrange(0, min(len(tokenized[rand_trans]), size) - MIN_LEN)\n",
    "        rand_length = random.randrange(1, (min(len(tokenized[rand_trans]), size)) - rand_start)\n",
    "        \n",
    "        temp = tokenized[rand_trans][rand_start:rand_start+rand_length]\n",
    "        for i in range(size-rand_length):\n",
    "            temp.append(0)\n",
    "\n",
    "        X1.append(np.array(temp))\n",
    "        X2.append(tokenizedDescs[rand_trans])\n",
    "        Y.append(tokenized[rand_trans][rand_length])\n",
    "        \n",
    "    X1 = np.array(X1)\n",
    "    X2 = np.array(X2)\n",
    "    Y = np.array(Y)\n",
    "    \n",
    "    X1 = to_categorical(X1, num_classes=len(lib))\n",
    "    X2 = to_categorical(X2, num_classes=len(lib))\n",
    "    Y = to_categorical(Y, num_classes=len(lib))\n",
    "    return X1, X2, Y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf3f7ac2",
   "metadata": {},
   "source": [
    "<h1>Problem #3: Building the model</h1>\n",
    "<br></br>\n",
    "<p>Gettting the data prepped is always the most annoying and difficult part. This time (for me at least) was no exception. I spent a good 2 hours writing the above cells, and now I'm ready to move on. Luckily, with everything put into place, it should IN THEORY be easy to set this model up.</p>\n",
    "<p>I already went over the plan in an above cell, so I won't explain myself again. This is already a stupid idea, I'm just going to roll with it at this point. I'm going to start with one GRU layer for each input layer, and then move on from there depending on how the model performs. I'll make sure to update this cell if I decide to change the model design drastically (which I most likely will do). I also plan on comparing the difference in performance between a LSTM model and a GRU model, so I'll document my findings later down the line. I feel like GRU will perform better, but I'll test both models just to be sure.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e583fb19",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-25T05:05:17.266922Z",
     "start_time": "2023-08-25T05:05:17.248923Z"
    }
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential, Model, load_model\n",
    "from tensorflow.keras.layers import Input, Embedding, Dense, GRU, LSTM, Dropout, BatchNormalization, concatenate, TimeDistributed, Flatten\n",
    "from tensorflow.keras.layers import LeakyReLU\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "def GRUModel():\n",
    "    #transcript input\n",
    "    x_in = Input(shape=(MAX_SEQ_LEN, len(lib)))\n",
    "    \n",
    "    x = GRU(128, return_sequences=True)(x_in)\n",
    "    x = LeakyReLU()(x)\n",
    "    \n",
    "    x = Model(inputs=x_in, outputs=x)\n",
    "    \n",
    "    #description input\n",
    "    y_in = Input(shape=(MAX_SEQ_LEN, len(lib)))\n",
    "    \n",
    "    y = GRU(128, return_sequences=True)(y_in)\n",
    "    y = LeakyReLU()(y)\n",
    "    \n",
    "    y = Model(inputs=y_in, outputs=y)\n",
    "    \n",
    "    #combine\n",
    "    z = concatenate([x.output, y.output])\n",
    "    \n",
    "    z = TimeDistributed(Dense(128))(z)\n",
    "    z = TimeDistributed(LeakyReLU())(z)\n",
    "    z = TimeDistributed(Dropout(0.2))(z)\n",
    "    \n",
    "    z = Flatten()(z)\n",
    "    \n",
    "    z = Dense(len(lib), activation='softmax')(z)\n",
    "    \n",
    "    z = Model(inputs=[x_in, y_in], outputs=z)\n",
    "    return z\n",
    "\n",
    "def LSTMModel():\n",
    "    #transcript input\n",
    "    x_in = Input(shape=(MAX_SEQ_LEN))\n",
    "    \n",
    "    x = Embedding(len(lib), 20, input_length=1)(x_in)\n",
    "    x = LSTM(300)(x)\n",
    "    x = Dropout(0.2)(x)\n",
    "    \n",
    "    x = Dense(200)(x)\n",
    "    x = Dropout(0.15)(x)\n",
    "    \n",
    "    x = Model(inputs=x_in, outputs=x)\n",
    "    \n",
    "    #description input\n",
    "    y_in = Input(shape=(maxDescLen))\n",
    "    \n",
    "    y = Embedding(len(lib), 20, input_length=1)(y_in)\n",
    "    y = LSTM(300)(y)\n",
    "    y = Dropout(0.2)(y)\n",
    "    \n",
    "    y = Dense(200)(y)\n",
    "    y = Dropout(0.2)(y)\n",
    "    \n",
    "    y = Model(inputs=y_in, outputs=y)\n",
    "    \n",
    "    #combine\n",
    "    z = concatenate([x.output, y.output])\n",
    "    \n",
    "    z = Dense(128, activation='relu')(z)\n",
    "    \n",
    "    z = Dense(len(lib), activation='softmax')(z)\n",
    "    \n",
    "    z = Model(inputs=[x_in, y_in], outputs=z)\n",
    "    return z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bb8646ef",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-25T05:05:18.468451Z",
     "start_time": "2023-08-25T05:05:17.861388Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            [(None, 250, 95)]    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_3 (InputLayer)            [(None, 250, 95)]    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "gru_1 (GRU)                     (None, 250, 128)     86400       input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "gru_2 (GRU)                     (None, 250, 128)     86400       input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu (LeakyReLU)         (None, 250, 128)     0           gru_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_1 (LeakyReLU)       (None, 250, 128)     0           gru_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 250, 256)     0           leaky_re_lu[0][0]                \n",
      "                                                                 leaky_re_lu_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed (TimeDistribut (None, 250, 128)     32896       concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_1 (TimeDistrib (None, 250, 128)     0           time_distributed[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_2 (TimeDistrib (None, 250, 128)     0           time_distributed_1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 32000)        0           time_distributed_2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 95)           3040095     flatten[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 3,245,791\n",
      "Trainable params: 3,245,791\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model = GRUModel()\n",
    "\n",
    "opt = Adam(learning_rate=0.0005)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=opt, metrics=['accuracy'])\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5921be10",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-25T05:06:01.548555Z",
     "start_time": "2023-08-25T05:05:26.526834Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1000/1000: LOSS=3.3619163036346436    ACC=0.10000000149011612\n",
      "Finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x17d7fb05fd0>,\n",
       " <matplotlib.lines.Line2D at 0x17d7fb1b070>]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#fitting the model (please god please work please)\n",
    "from IPython.display import clear_output\n",
    "\n",
    "epochs = 1000\n",
    "batch_size = 20\n",
    "\n",
    "losses = []\n",
    "\n",
    "for i in range(epochs):\n",
    "    #generate some data\n",
    "    X1, X2, Y = get_dataset(batch_size, MAX_SEQ_LEN)\n",
    "\n",
    "    #train the network\n",
    "    loss = model.train_on_batch([X1, X2], Y)\n",
    "    losses.append(loss)\n",
    "    \n",
    "    clear_output(wait=True)\n",
    "    print(f\"Epoch {i+1}/{epochs}: LOSS={loss[0]}    ACC={loss[1]}\")\n",
    "\n",
    "print(\"Finished\")\n",
    "model.save(\"../SpongeBobLSTM.h5\")\n",
    "plt.plot(losses)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e193c75",
   "metadata": {},
   "source": [
    "<h1>Problem #4: Testing the model</h1>\n",
    "<br></br>\n",
    "<p>Now that I have a trainable model, I need a way of testing it's capabilities outside of a graph. My goal is to create a program that takes a prompt, tokenizes and processes the prompt, and then passes it through the model until the model generates a story as big as what it can take as input (if that makes any sense). Hopefully the code should explain itself for this one as I'll be using a lot of the code I already written.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "c0fbb8ed",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-24T05:26:04.618053Z",
     "start_time": "2023-08-24T05:25:45.032669Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter prompt for episode: spongebob kills his friend\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3b929eb19f33473292552ca88c2ad0e1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/245 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "migger the episode begins with . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n"
     ]
    }
   ],
   "source": [
    "from tqdm.notebook import tqdm as log_progress\n",
    "\n",
    "#how many tokens to take from the actual dataset \n",
    "start_seq_len = 5\n",
    "\n",
    "prompt = input(\"Enter prompt for episode: \")\n",
    "prompt = prompt.lower()\n",
    "\n",
    "#tokenize the prompt if it's short enough\n",
    "if len(prompt.split(' ')) < MAX_SEQ_LEN:\n",
    "    tokens = tokenize(prompt)\n",
    "    ep_prompt = []\n",
    "    \n",
    "    for i in tokens:\n",
    "        if i in lib:\n",
    "            ep_prompt.append(lib.index(i))\n",
    "        else:\n",
    "            ep_prompt.append(0)\n",
    "            \n",
    "    for i in range(MAX_SEQ_LEN-len(ep_prompt)):\n",
    "        ep_prompt.append(0)\n",
    "        \n",
    "    ep_prompt = np.array(ep_prompt)\n",
    "    ep_prompt = np.reshape(ep_prompt, (1, ep_prompt.shape[0]))\n",
    "    \n",
    "    #create a temp array to hold the previous tokens of the generated story\n",
    "    episode = np.zeros((1, MAX_SEQ_LEN))\n",
    "    episode[0][0:start_seq_len] = random.choice(tokenized)[0:start_seq_len]\n",
    "    \n",
    "    episode[0][0] = random.randrange(0, len(lib)) #start with a random token\n",
    "    \n",
    "    counter = start_seq_len\n",
    "    for i in log_progress(range(MAX_SEQ_LEN-start_seq_len)):\n",
    "        next_token = model.predict([episode, ep_prompt], verbose=0)\n",
    "        episode[0][counter] = next_token[0].argmax()\n",
    "        counter += 1\n",
    "        \n",
    "    #finally print the finished story\n",
    "    episode_script = ''\n",
    "    for i in episode[0]:\n",
    "        episode_script += lib[int(i)] + ' '\n",
    "        \n",
    "    print(episode_script)\n",
    "else:\n",
    "    print(\"Prompt is too long!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9407aed4",
   "metadata": {},
   "source": [
    "<h2>Some notes:</h2>\n",
    "<ol>\n",
    "    <li>Embedding layer might not be that useful. I'm just trying to understand and generate sequences, not get the AI to understand the difference between words.</li>\n",
    "    <li>If embedding layers are useless, switching to a character based tokenization might be better than the word based tokenization method I'm using now.</li>\n",
    "    <li>The AI currently does not seem to understand any differences. I've changed the architecture of the model several times with no change in it's performance, so I'm going to guess the problem lies with how I'm feeding and prepping the data.</li>\n",
    "</ol>\n",
    "<br></br>\n",
    "<h3>Performance notes after changing data to character-based tokenization:</h3>\n",
    "<ul>\n",
    "    <li>Doesn't seem to be any change in performance, but I just started with this new strategy, so I'm going to put a little more work into it.</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daa52b1f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
