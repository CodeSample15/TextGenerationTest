{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b8ecbc4f",
   "metadata": {},
   "source": [
    "<h1>I hate myself for attempting this but I'm bored</h1>\n",
    "<br></br>\n",
    "<h3>Let me explain myself because I feel this needs explaining:</h3>\n",
    "<p>Recently, the GPT model has dominated the text-generation realm of AI (as it should, it's fucking amazing). However, I want to see how far I can push the RNN model for text generation before it can't be pushed any further. Of course, conditional text generation has been done before in the past with RNN, and very well, BUT: I am stubborn as fuck and need to experiment by myself to see what I can do. Also I just finished working on a video game and need a not so overcomplicated project to suck me back into the world of AI. I'll document my findings here in this notebook so you can see the deterioration of my sanity.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "daa4505f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-05T03:50:13.189218Z",
     "start_time": "2023-09-05T03:50:13.173628Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import glob\n",
    "from time import sleep\n",
    "\n",
    "from bs4 import BeautifulSoup as bs4\n",
    "import requests\n",
    "\n",
    "DESC_FILE = 'ep_descs.pkl'\n",
    "TRANS_FILE = 'C:/Users/lukec/Documents/Datasets/SpongeBob_SquarePants_Transcripts/'\n",
    "\n",
    "MAX_SEQ_LEN = 40"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6be69ec7",
   "metadata": {},
   "source": [
    "<h2>Problem #1: web scraping</h2>\n",
    "<br></br>\n",
    "<p>In order to get the generator to generate scripts from a prompt, I need to get descriptions of each episode (which will be the prompts of this generator). Fortunately, this data can be found on the Spongebob Wiki. Unfortunately, this means I have to do some mother-fucking web scraping. I'll try explain what I'm doing with comments but to be honest, I'm going to give up on that pretty quickly. Sorry in advance for my ugly python code</p>\n",
    "<p>For ease of use later on, I'll store the data (which will be kept in a dictionary) into a seperate file using python's pickle</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a2417651",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-05T01:13:38.509634Z",
     "start_time": "2023-09-05T01:13:31.277824Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished\n"
     ]
    }
   ],
   "source": [
    "#running for each season of spongebob\n",
    "SEASONS = 13\n",
    "data = {}\n",
    "\n",
    "for season in range(1, SEASONS+1):\n",
    "    page = requests.get(f\"https://spongebob.fandom.com/wiki/Season_{season}#List_of_episodes\").content\n",
    "    \n",
    "    soup = bs4(page, 'html.parser')\n",
    "    table = soup.find_all('table', class_='general')[0]\n",
    "        \n",
    "    #let's get the title and descriptions of each episode\n",
    "    titles = table.find_all('td', style='text-align:left')\n",
    "    descriptions = table.find_all('td', colspan='4')\n",
    "    \n",
    "    for j in range(len(titles)):\n",
    "        title = titles[j].text\n",
    "        desc = descriptions[j].text\n",
    "        #getting rid of the quotation marks around the episode name with possibly the most python line of code ever written (then also do some other pre processing)\n",
    "        title = title[1:-2]\n",
    "        title = title.replace(' ', '')\n",
    "        title = title.lower()\n",
    "        \n",
    "        data[title] = desc #updating the dataset\n",
    "        \n",
    "#save the compiled data to a file\n",
    "with open(DESC_FILE, 'wb') as f:\n",
    "    pickle.dump(data, f)\n",
    "\n",
    "print(\"Finished\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cceeadb8",
   "metadata": {},
   "source": [
    "<p>Alright, that wasn't as bad as I thought it would be. I ended up getting the script to work on the third or fourth time. Luckily the spongebob wiki doesn't require javascript to load its shit, so I didn't have to boot up selenium to get this scraper to work. Come to think of it, this was probably the best experience I've had writing a web scraper. Nice</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e18a47c",
   "metadata": {},
   "source": [
    "<h1>Problem #2: bringing both datasets together</h1>\n",
    "<br></br>\n",
    "<p>Now that I have all the data I need, I need to compile everything into a single dataset that I can use to train the network with. This means for the transcripts, I have to clean, tokenize, and pad everything. For the episode descriptions, I need to combine the descriptions with the correct transcripts.</p>\n",
    "<p>Some things to consider: RNN models are notoriously bad at generating long sequences of text. Should I set the sampling size lower so that the model performs better? Or should I keep it high so I can really test the limits of this type of model. Hmmmm.... I guess I'll figure it out as I go, but I'm pretty sure I'm going to have to set the sampling size to be smaller. I'll start with the full transcripts and go from there. I think the main reason I want to do this is because I already know how bad LSTM is at performing this task, but I haven't really tested the GRU layer that much and am curious as to how it performs. I think I'll end up training two models.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de593a2b",
   "metadata": {},
   "source": [
    "<h3>Quick side note:</h3>\n",
    "<p>I want to really quickly go over in text what I want the architecture of the model to be (inputs and outputs for now, I'll go into more detail when I build the model). For starters, the model will have two inputs: X1 and X2. They will store the previous text in the transcript and the prompt, respectively. The output will be a one-hot encoding of the next token to be added to the sequence. My hope with using the two seperate inputs for the model will help it perform better when generating scripts that are more relevant to the provided episode prompt. Again, GPT models handle this problem with ease, but when it comes to RNNs, I want to make sure the model remembers what it should be generating</p>\n",
    "<p>I'll go with this design for as long as possible, so hopefully I don't lose my shit trying to keep this plan from failing. I have to remember that this is not going to work the first time cuz I have no clue what the fuck I'm doing.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bc50dd7d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-05T03:47:48.005090Z",
     "start_time": "2023-09-05T03:47:47.514608Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "76 items failed to load\n",
      "317 items loaded!\n"
     ]
    }
   ],
   "source": [
    "#let's start with the basics: loading the data from disk\n",
    "dataset = {}\n",
    "\n",
    "descs = {}\n",
    "with open(DESC_FILE, 'rb') as f:\n",
    "    descs = pickle.load(f)\n",
    "\n",
    "failed_items = 0\n",
    "successful_items = 0\n",
    "    \n",
    "for file in glob.glob(TRANS_FILE + '*.txt'):\n",
    "    ep_title = file.split('\\\\')[1].split('.')[0]\n",
    "    ep_title = ep_title.lower()\n",
    "    \n",
    "    #try to access the description of the episode, if it's not on file, just ignore it\n",
    "    try:\n",
    "        desc = descs[ep_title]\n",
    "        \n",
    "        lines = []\n",
    "        with open(file, 'r', encoding='utf-8') as f:\n",
    "            for line in f.readlines():\n",
    "                lines.append(line.lower())\n",
    "                #lines.extend('\\n')\n",
    "        \n",
    "        dataset[desc] = lines\n",
    "        successful_items += 1\n",
    "    except:\n",
    "        failed_items += 1\n",
    "        continue\n",
    "\n",
    "print(f\"{failed_items} items failed to load\")\n",
    "print(f\"{successful_items} items loaded!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1f6959a2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-05T03:49:17.777171Z",
     "start_time": "2023-09-05T03:47:51.849566Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing data...\n",
      "Finished\n"
     ]
    }
   ],
   "source": [
    "#alright, now let's process and organize this data (spaghetti code incoming)\n",
    "print(\"Processing data...\")\n",
    "\n",
    "pretokenized = []\n",
    "pretokenizedDescs = []\n",
    "\n",
    "def tokenize(line):\n",
    "    #not even going to explain this mess. Just know this cleans the data. Don't currently know a better way of doing this and it's killing me inside. \n",
    "    tokens = []\n",
    "    for char in line:\n",
    "        tokens.append(char)\n",
    "    return tokens\n",
    "\n",
    "def tokenize_words(line):\n",
    "    #not even going to explain this mess. Just know this cleans the data. Don't currently know a better way of doing this and it's killing me inside. \n",
    "    tokens = []\n",
    "    for word in line.split(' '):\n",
    "        newword = \"\"\n",
    "        for char in word:\n",
    "            if not char.isalpha():\n",
    "                if newword != \"\":\n",
    "                    tokens.append(newword)\n",
    "                newword = \"\"\n",
    "                tokens.append(char)\n",
    "            else:\n",
    "                newword += char\n",
    "        if(newword!=''):\n",
    "            tokens.append(newword)\n",
    "    return tokens\n",
    "\n",
    "for desc in dataset:\n",
    "    #clean the data\n",
    "    tempdata = [x for x in dataset[desc] if x != '\\n']\n",
    "    tokens = []\n",
    "    descTokens = []\n",
    "    \n",
    "    for line in tempdata:\n",
    "        line += \"\\n\"\n",
    "        tokens.extend(tokenize_words(line))\n",
    "        \n",
    "    pretokenizedDescs.append(tokenize_words(desc.lower()))\n",
    "    #removing unecessary tokens\n",
    "    pretokenizedDescs[-1].pop(pretokenizedDescs[-1].index('\\n'))\n",
    "    \n",
    "    pretokenized.append(tokens)\n",
    "    \n",
    "#now let's tokenize this sucker and then move on to building the dataset to be fed to the network.\n",
    "lib = [''] #library of tokens\n",
    "tokenized = [] #dataset tokenized\n",
    "tokenizedDescs = [] #same thing but descriptions\n",
    "maxLen = 0 #for padding later down the road\n",
    "maxDescLen = 0 #same thing but for descriptions\n",
    "\n",
    "#first the transcripts (calculating the maximum sequence length and then tokenizing the dataset using the lib array)\n",
    "for i in pretokenized:\n",
    "    if len(i) > maxLen:\n",
    "        maxLen = len(i)\n",
    "    for j in i:\n",
    "        if j not in lib:\n",
    "            lib.append(j)\n",
    "            \n",
    "for i in pretokenized:\n",
    "    temp = []\n",
    "    for j in i:\n",
    "        temp.append(lib.index(j))\n",
    "    tokenized.append(temp)\n",
    "    \n",
    "#now the descriptions\n",
    "for i in pretokenizedDescs:\n",
    "    if len(i) > maxDescLen:\n",
    "        maxDescLen = len(i)\n",
    "    for j in i: #continuing to build upon the library just in case there are some tokens that didn't make the list yet\n",
    "        if j not in lib:\n",
    "            lib.append(j)\n",
    "            \n",
    "for i in pretokenizedDescs:\n",
    "    temp = []\n",
    "    for j in i:\n",
    "        temp.append(lib.index(j))\n",
    "    tokenizedDescs.append(temp)\n",
    "    \n",
    "#now we need to pad the tokenized descriptions since that won't happen automatically when the dataset it built\n",
    "for i, n in enumerate(tokenizedDescs):\n",
    "    for j in range(maxDescLen-len(n)):\n",
    "        tokenizedDescs[i].append(0) #padding (0 token represents and empty string in the lib array)\n",
    "\n",
    "print(\"Finished\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ce3b6b91",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-05T03:50:51.637563Z",
     "start_time": "2023-09-05T03:50:45.018039Z"
    }
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import to_categorical\n",
    "import random\n",
    "\n",
    "#smallest length a sequence can be\n",
    "MIN_LEN = MAX_SEQ_LEN\n",
    "\n",
    "X1 = [] #ep descriptions\n",
    "X2 = [] #prev tokens\n",
    "Y = []  #ep transcipts\n",
    "\n",
    "#helper to generate random batches of data from the main dataset\n",
    "#loading the whole dataset to memory at one time on my 16GB of ram would fry my computer pretty quickly. Let's avoid that\n",
    "def get_dataset(batch_size, size=MAX_SEQ_LEN):\n",
    "    X1 = []\n",
    "    X2 = []\n",
    "    Y = []\n",
    "    for batch in range(batch_size):\n",
    "        rand_trans = random.randrange(MIN_LEN, len(tokenized)) #get a random transcript to get information from\n",
    "        rand_start = random.randrange(0, len(tokenized[rand_trans])-size)\n",
    "        \n",
    "        temp = tokenized[rand_trans][rand_start:rand_start+size]\n",
    "\n",
    "        X1.append(np.array(temp))\n",
    "        X2.append(tokenizedDescs[rand_trans])\n",
    "        Y.append(tokenized[rand_trans][rand_start+size])\n",
    "        \n",
    "    X1 = np.array(X1, dtype='float32')\n",
    "    X2 = np.array(X2, dtype='float32')\n",
    "    Y = np.array(Y)\n",
    "    \n",
    "    Y = to_categorical(Y, num_classes=len(lib))\n",
    "    return X1, X2, Y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf3f7ac2",
   "metadata": {},
   "source": [
    "<h1>Problem #3: Building the model</h1>\n",
    "<br></br>\n",
    "<p>Gettting the data prepped is always the most annoying and difficult part. This time (for me at least) was no exception. I spent a good 2 hours writing the above cells, and now I'm ready to move on. Luckily, with everything put into place, it should IN THEORY be easy to set this model up.</p>\n",
    "<p>I already went over the plan in an above cell, so I won't explain myself again. This is already a stupid idea, I'm just going to roll with it at this point. I'm going to start with one GRU layer for each input layer, and then move on from there depending on how the model performs. I'll make sure to update this cell if I decide to change the model design drastically (which I most likely will do). I also plan on comparing the difference in performance between a LSTM model and a GRU model, so I'll document my findings later down the line. I feel like GRU will perform better, but I'll test both models just to be sure.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e583fb19",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-05T04:12:19.005004Z",
     "start_time": "2023-09-05T04:12:18.971126Z"
    }
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Input, Embedding, Dense, GRU, LSTM, Dropout, BatchNormalization, concatenate, TimeDistributed, Flatten\n",
    "from tensorflow.keras.layers import LeakyReLU\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "def GRUModel():\n",
    "    #transcript input\n",
    "    x_in = Input(shape=(MAX_SEQ_LEN))\n",
    "    \n",
    "    x = Embedding(len(lib), 20, input_length=1)(x_in)\n",
    "    \n",
    "    x = GRU(128)(x)\n",
    "    \n",
    "    x = Model(inputs=x_in, outputs=x)\n",
    "    \n",
    "    #descriptions input\n",
    "    y_in = Input(shape=(maxDescLen))\n",
    "    \n",
    "    y = Embedding(len(lib), 20, input_length=1)(y_in)\n",
    "    \n",
    "    y = GRU(64)(y)\n",
    "    \n",
    "    y = Model(inputs=y_in, outputs=y)\n",
    "    \n",
    "    #models combined\n",
    "    z = concatenate([x.input, y.input])\n",
    "    \n",
    "    z = Dense(128)(z)\n",
    "    z = LeakyReLU()(z)\n",
    "    z = Dropout(0.2)(z)\n",
    "    \n",
    "    z = Dense(len(lib), activation='softmax')(z)\n",
    "    \n",
    "    z = Model(inputs=[x_in, y_in], outputs=z)\n",
    "    return z\n",
    "\n",
    "def LSTMModel():\n",
    "    #transcript input\n",
    "    x_in = Input(shape=(MAX_SEQ_LEN))\n",
    "    \n",
    "    x = Embedding(len(lib), 20, input_length=1)(x_in)\n",
    "    \n",
    "    x = LSTM(128)(x)\n",
    "    \n",
    "    x = Model(inputs=x_in, outputs=x)\n",
    "    \n",
    "    #descriptions input\n",
    "    y_in = Input(shape=(maxDescLen))\n",
    "    \n",
    "    y = Embedding(len(lib), 20, input_length=1)(y_in)\n",
    "    \n",
    "    y = LSTM(64)(y)\n",
    "    \n",
    "    y = Model(inputs=y_in, outputs=y)\n",
    "    \n",
    "    #models combined\n",
    "    z = concatenate([x.input, y.input])\n",
    "    \n",
    "    z = Dense(128)(z)\n",
    "    z = LeakyReLU()(z)\n",
    "    z = Dropout(0.2)(z)\n",
    "    \n",
    "    z = Dense(len(lib), activation='softmax')(z)\n",
    "    \n",
    "    z = Model(inputs=[x_in, y_in], outputs=z)\n",
    "    return z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bb8646ef",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-05T04:12:21.319421Z",
     "start_time": "2023-09-05T04:12:19.538031Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_5\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_3 (InputLayer)            [(None, 40)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_4 (InputLayer)            [(None, 39)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 79)           0           input_3[0][0]                    \n",
      "                                                                 input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 128)          10240       concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_1 (LeakyReLU)       (None, 128)          0           dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 128)          0           leaky_re_lu_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 17867)        2304843     dropout_2[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 2,315,083\n",
      "Trainable params: 2,315,083\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model = LSTMModel()\n",
    "\n",
    "opt = Adam(learning_rate=0.0003)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=opt, metrics=['accuracy'])\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5921be10",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-05T04:27:26.565616Z",
     "start_time": "2023-09-05T04:25:36.634651Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1000/1000: LOSS=6.1157636642456055    ACC=0.0625\n",
      "Finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x2618a6358b0>,\n",
       " <matplotlib.lines.Line2D at 0x2618a635d90>]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#fitting the model (please god please work please)\n",
    "from IPython.display import clear_output\n",
    "\n",
    "epochs = 1000\n",
    "batch_size = 128\n",
    "\n",
    "losses = []\n",
    "\n",
    "for i in range(epochs):\n",
    "    #generate some data\n",
    "    X1, X2, Y = get_dataset(batch_size, MAX_SEQ_LEN)\n",
    "\n",
    "    #train the network\n",
    "    loss = model.train_on_batch([X1, X2], Y)\n",
    "    losses.append(loss)\n",
    "    \n",
    "    clear_output(wait=True)\n",
    "    print(f\"Epoch {i+1}/{epochs}: LOSS={loss[0]}    ACC={loss[1]}\")\n",
    "\n",
    "print(\"Finished\")\n",
    "model.save(\"SpongeBobLSTM.h5\")\n",
    "plt.plot(losses)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e193c75",
   "metadata": {},
   "source": [
    "<h1>Problem #4: Testing the model</h1>\n",
    "<br></br>\n",
    "<p>Now that I have a trainable model, I need a way of testing it's capabilities outside of a graph. My goal is to create a program that takes a prompt, tokenizes and processes the prompt, and then passes it through the model until the model generates a story as big as what it can take as input (if that makes any sense). Hopefully the code should explain itself for this one as I'll be using a lot of the code I already written.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "262ab4f0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-05T04:27:51.024286Z",
     "start_time": "2023-09-05T04:27:33.034877Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter prompt for episode: Spongebob finds a rare sea shell\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7b5273d428874ddeb767026738e703e4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=50.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "spongebob : good morning , bikini bottom ! ahhh , what a beautiful day ! [ spongebob ' s hand appears from a sand castle pineapple with his face drawn on his hand ] i wonder if patrick ' s \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " . \n",
      " . \n",
      " \n",
      " . \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n"
     ]
    }
   ],
   "source": [
    "from tqdm.notebook import tqdm as log_progress\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "def shift(arr, new=0.0):\n",
    "    for i in range(1, len(arr[0])):\n",
    "        arr[0][i-1] = arr[0][i]\n",
    "    arr[0][-1] = new\n",
    "\n",
    "model = load_model(\"SpongebobLSTM.h5\")\n",
    "\n",
    "#how many tokens to take from the actual dataset \n",
    "start_seq_len = MAX_SEQ_LEN\n",
    "EP_LEN = 50 #how many times the program should run\n",
    "\n",
    "prompt = input(\"Enter prompt for episode: \")\n",
    "prompt = prompt.lower()\n",
    "\n",
    "#tokenize the prompt if it's short enough\n",
    "if len(prompt.split(' ')) < maxDescLen:\n",
    "    tokens = tokenize_words(prompt)\n",
    "    ep_prompt = []\n",
    "    \n",
    "    for i in tokens:\n",
    "        if i in lib:\n",
    "            ep_prompt.append(lib.index(i))\n",
    "        else:\n",
    "            ep_prompt.append(0)\n",
    "            \n",
    "    for i in range(maxDescLen-len(ep_prompt)):\n",
    "        ep_prompt.append(0)\n",
    "        \n",
    "    ep_prompt = np.array(ep_prompt)\n",
    "    ep_prompt = np.reshape(ep_prompt, (1, ep_prompt.shape[0]))\n",
    "    \n",
    "    #create a temp array to hold the previous tokens of the generated story\n",
    "    episode = []\n",
    "    \n",
    "    temp = np.zeros((1, MAX_SEQ_LEN))\n",
    "    temp[0][0:start_seq_len] = random.choice(tokenized)[0:start_seq_len]\n",
    "    \n",
    "    for i in range(start_seq_len):\n",
    "        episode.append(int(temp[0][i]))\n",
    "    \n",
    "    for i in log_progress(range(EP_LEN)):\n",
    "        next_token = model.predict([temp, ep_prompt], verbose=0)\n",
    "        episode.append(int(next_token[0].argmax()))\n",
    "        shift(temp, new=next_token[0].argmax())\n",
    "        \n",
    "    #finally print the finished story\n",
    "    episode_script = ''\n",
    "    for i in episode:\n",
    "        episode_script += lib[i] + ' '\n",
    "        \n",
    "    print(episode_script)\n",
    "else:\n",
    "    print(\"Prompt is too long!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9407aed4",
   "metadata": {},
   "source": [
    "<h2>Some notes:</h2>\n",
    "<ol>\n",
    "    <li>Embedding layer might not be that useful. I'm just trying to understand and generate sequences, not get the AI to understand the difference between words.</li>\n",
    "    <li>If embedding layers are useless, switching to a character based tokenization might be better than the word based tokenization method I'm using now.</li>\n",
    "    <li>The AI currently does not seem to understand any differences. I've changed the architecture of the model several times with no change in it's performance, so I'm going to guess the problem lies with how I'm feeding and prepping the data.</li>\n",
    "</ol>\n",
    "<br></br>\n",
    "<h3>Performance notes after changing data to character-based tokenization:</h3>\n",
    "<ul>\n",
    "    <li>Doesn't seem to be any change in performance, but I just started with this new strategy, so I'm going to put a little more work into it.</li>\n",
    "    <li>Not sure if it was the character based tokenization or the fact that the model isn't training on empty inputs anymore (no more 0 padding in training data), but the model is now actually performing better. I also simplified the model a bit to only take one input (previous tokens) in order to debug the lack of learning, which also could contribute to this boost in performance. I'm going to add back the second input with this new method and see if there's any changes.</li>\n",
    "    <li>It seems to be the fact that input data is no longer padded that the model is performing better than ever. I am going to try and go back to the old tokenization method to see if that will change anything.</li>\n",
    "</ul>\n",
    "\n",
    "<h3>Notes after changing back to word-based tokenization:</h3>\n",
    "<ul>\n",
    "    <li>I included the loss (blue) and accuracy (orange) graph below:</li>\n",
    "    <img src='Graph1.png'>\n",
    "    <li>As you can see, the training is unstable as fuck, but it is slowly getting better over time, which is good. I'm going to add back the second input as well as testing the model with what it can currently produce. After making those changes, I got this graph:</li>\n",
    "    <img src='Graph2.png'>\n",
    "    <li>No idea what the fuck happened here. Amazing how the loss started so high at first, but that might be just from the extra neurons I threw into the model. To make sure the first input isn't the only part of the model training, I'll add some dropout to both inputs and also mess with the Embedding layers for both inputs.</li>\n",
    "    <li>So this is disappointing:</li>\n",
    "    <img src='Graph3.png'>\n",
    "    <li>It seems that the model is no longer improving after training some more... This is annoying.</li>\n",
    "</ul>\n",
    "<br></br>\n",
    "<h3>Let's talk validation data:</h3>\n",
    "<h4>(and why this approach I'm taking is terrible)</h4>\n",
    "<p>Many people who aren't trying to kill their careers in ML will use validation data to make sure their model is actually learning rather than memorizing a dataset. This is smart. It introduces new data to the model that it hasn't seen before and allows for programmers to see if their model is overfitting or not. So why am I not using validation data?</p>\n",
    "<br></br>\n",
    "<p>Well, the answer is simple. <b>I'm stupid and stubborn</b>. I am feeding the network very little data. You might say \"there's so much training data in the episode transcripts, you have no excuse\", and you're right, but I am also feeding to the network the descriptions for each episode, which is very little information to the network. There's only so many descriptions, and while I can split up the transcripts to get more training data, I can't split up sequences as little as descriptions, especially when I need the whole desc sequence to actually represent a description for an episode.</p>\n",
    "<p>I mean, if I'm being honest it's not the worse solution. I mean, think about it: In theory this will produced an overfitted model that generates infinite episodes given the topic of any existing spongebob episode. In theory, at least.</p>\n",
    "<br></br>\n",
    "<h3>A slightly better approach:</h3>\n",
    "<h4>(Apart from using something like the GPT model)</h4>\n",
    "<p>Transfer learning. Use a model that already has a fully trained Embedding and LSTM/GRU layer and slap it to the top of my model. This would give the model a giant boost, but I'm still not sure how well it would do. Might experiment with this in the future...</p>\n",
    "\n",
    "<br></br>\n",
    "\n",
    "<h1>Results:</h1>\n",
    "<h4>(Prompt used: Spongebob finds a rare sea shell)</h4>\n",
    "\n",
    "<br></br>\n",
    "\n",
    "<h3>GRU Model:</h3>\n",
    "<p>After 1000 epochs:</p>\n",
    "<img src='Results1.png'>\n",
    "<p>After 2000 epochs: (Seems like it's getting better(?))</p>\n",
    "<img src='Results2.png'>\n",
    "<p>After 3000 epochs:</p>\n",
    "<p>No image here because the output is just a bunch of whitespace interrupted by a lot of periods and the occasional \"squidward\"...</p>\n",
    "<br></br>\n",
    "<p>Damn it</p>\n",
    "<br>After 4000 epochs:</br>\n",
    "<p>...It's just whitespace</p>\n",
    "<p><b>FUCK</b></p>\n",
    "<br></br>\n",
    "<p>Well, hopefully I can maybe salvage this experiment by getting some interesting results with LSTM to compare to GRU.</p>\n",
    "<br></br>\n",
    "\n",
    "<h3>LSTM Model:</h3>\n",
    "<p>After 1000 epochs:</p>\n",
    "<img src='Results3.png'>\n",
    "<p>After 2000 epochs: (noticing a trend here)</p>\n",
    "<img src='Results4.png'>\n",
    "<p>After 3000 epochs:</p>\n",
    "<img src='Results5.png'>\n",
    "<p>After 4000 epochs:</p>\n",
    "<p>Whitespace again...</p>\n",
    "\n",
    "<br></br>\n",
    "\n",
    "<p>Alright, back to the drawing board.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daa52b1f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72978487",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
